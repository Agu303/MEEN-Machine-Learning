

import matplotlib.pyplot as plt
import numpy as np

#1.1
i = [1,2,3]
x1 = [1,0,0]
x2 = [0,1,0]
y = [0,0,1]

fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.scatter(x1, x2, y, color='m', marker='o')  # 'r' stands for red, 'o' for circle markers
ax.set_xlabel('X ')
ax.set_ylabel('X2 ')
ax.set_zlabel('Y ')

plt.show()

#1.2
#vectors
y = np.array([0, 0, 1])
x1 = np.array([1, 0, 0])
x2 = np.array([0, 1, 0])
w = np.array([0, 0, 0])  # for example, initialize w = [w0, w1, w2]
X = np.column_stack([x1, x2])
y_hat = X.dot(w[1:])  # x1*w1 + x2*w2 (excluding w0 because w0 corresponds to the bias term)
difference = y - y_hat  # Only the first two elements of y are relevant to the linear combination

sse = np.sum(np.abs(difference)**2)

print('#2 Squared Error:', sse)
