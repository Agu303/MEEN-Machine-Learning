{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W3q_R0ZmkwC"
      },
      "source": [
        "Your `fit` and `predict` functions should not use any external libraries other than `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zeaU-v0ZmheU"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FN97TuQmIvb"
      },
      "source": [
        "Here should be your `fit` function. Please see detailed instructions on Canvas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MfjlTXOZmH1r"
      },
      "outputs": [],
      "source": [
        "def fit(X_data, Y_data, eta, n_epochs):\n",
        "    a,b = X_data.shape\n",
        "    X_data = np.hstack([np.ones((a,1)), X_data])\n",
        "    weights = np.zeros(b + 1)\n",
        "    for n in range(n_epochs):\n",
        "        for i in range(a):\n",
        "            j = np.dot(X_data[i], weights)\n",
        "            pred = sig(j)\n",
        "            grad = (pred - Ydata[i]) * X_data[i]\n",
        "\n",
        "            weights -= eta * grad\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX-6DdjToO7i"
      },
      "source": [
        "Here should be your `predic` function. Please see detailed instructions on Canvas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vYVxy3s_oTG0"
      },
      "outputs": [],
      "source": [
        "def predict(x, weights):\n",
        "    x = np.insert(x, 0, 1)\n",
        "    u = np.dot(x, weights)\n",
        "    pred = sig(u)\n",
        "\n",
        "    return 1 if pred >= 0.5 else 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcIShNNoUgZ"
      },
      "source": [
        "Below is the code to test your functions. To run it, you will need to download `Engine_Condition.csv` (or `Engine_Condition_Comp.csv` if you modify the file name in the below code accordingly) provided on Canvas and put them in the same folder as this notebook.\n",
        "\n",
        "Note: While the `fit` and `predict` functions should work for an arbitrary number of features, the visualization code works only for problems with two features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GuM5Tsxilp9W"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sig' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     20\u001b[0m n_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 21\u001b[0m weights \u001b[38;5;241m=\u001b[39m fit(X_train, y_train, eta, n_epoch)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEARNED WEIGHTS :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# generate evaluation statistics for training and test set\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(X_data, Y_data, eta, n_epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(a):\n\u001b[0;32m      7\u001b[0m     j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_data[i], weights)\n\u001b[1;32m----> 8\u001b[0m     pred \u001b[38;5;241m=\u001b[39m sig(j)\n\u001b[0;32m      9\u001b[0m     grad \u001b[38;5;241m=\u001b[39m (pred \u001b[38;5;241m-\u001b[39m Ydata[i]) \u001b[38;5;241m*\u001b[39m X_data[i]\n\u001b[0;32m     11\u001b[0m     weights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m eta \u001b[38;5;241m*\u001b[39m grad\n",
            "\u001b[1;31mNameError\u001b[0m: name 'sig' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# import the data file\n",
        "df = pd.read_csv(\"Engine_Condition.csv\")       # linearly separable\n",
        "# df = pd.read_csv(\"Engine_Condition_Comp.csv\")    # not linearly separable\n",
        "feature_names = ['EV1', 'EV2']\n",
        "X_all = df[feature_names]\n",
        "y_all = df['Status']\n",
        "\n",
        "# split into training and test sets for holdout validation\n",
        "# cross validation would be a better approach with such a small dataset\n",
        "# converting from DataFrame to numpy arrays in the process\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all.to_numpy(), y_all.to_numpy(), random_state=42)\n",
        "\n",
        "# train the model and display the learned weights\n",
        "eta=0.1\n",
        "n_epoch=100\n",
        "weights = fit(X_train, y_train, eta, n_epoch)\n",
        "print(f'LEARNED WEIGHTS :\\n\\t{weights}')\n",
        "\n",
        "\n",
        "# generate evaluation statistics for training and test set\n",
        "N_train = X_train.shape[0]\n",
        "N_right = 0\n",
        "N_wrong = 0\n",
        "for i in range(N_train):\n",
        "\n",
        "    if abs(y_train[i]-predict(X_train[i,:],weights))>0.0:\n",
        "        N_wrong += 1\n",
        "    else:\n",
        "        N_right += 1\n",
        "train_accuracy = N_right/N_train\n",
        "\n",
        "\n",
        "print('\\nACCURACY STATISTICS')\n",
        "print('On training set:')\n",
        "print(f'\\t   total cases = {N_train:d}')\n",
        "print(f'\\t       correctly classified   = {N_right:d}')\n",
        "print(f'\\t       incorrectly classified = {N_wrong:d}')\n",
        "print(f'\\taccuracy = {100*train_accuracy:4.2f} %')\n",
        "\n",
        "\n",
        "N_test = X_test.shape[0]\n",
        "N_right = 0\n",
        "N_wrong = 0\n",
        "for i in range(N_test):\n",
        "    if abs(y_test[i]-predict(X_test[i,:],weights))>0.0:\n",
        "        N_wrong += 1\n",
        "    else:\n",
        "        N_right += 1\n",
        "test_accuracy = N_right/N_test\n",
        "\n",
        "print('On test set:')\n",
        "print(f'\\t   total cases = {N_test:d}')\n",
        "print(f'\\t       correctly classified   = {N_right:d}')\n",
        "print(f'\\t       incorrectly classified = {N_wrong:d}')\n",
        "print(f'\\taccuracy = {100*test_accuracy:4.2f} %')\n",
        "\n",
        "\n",
        "\n",
        "# plot the data and learned boundary\n",
        "# for simplicity, we are not distinguishing between training and test data\n",
        "\n",
        "# this step calculates points along the classification boundary\n",
        "# will fail if boundary is vertical (weights[2]==0)\n",
        "x1 = np.linspace(4.4, 6.3, num=2)\n",
        "x2 = - weights[0]/weights[2] - weights[1]/weights[2]*x1\n",
        "\n",
        "# separate data into class 1 and class 0\n",
        "# inefficient for very large sets (due to appending) but fine for us here\n",
        "indices1 = []\n",
        "indices0 = []\n",
        "for i in range(N_train+N_test):\n",
        "    if y_all[i] == 1.0:\n",
        "        indices1.append(i)\n",
        "    else:\n",
        "        indices0.append(i)\n",
        "\n",
        "df_arr = np.array(df)\n",
        "D0 = df_arr[indices0]\n",
        "D1 = df_arr[indices1]\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(D1[:, 0], D1[:, 1], marker='o', s=50, edgecolor='k', label='Good')\n",
        "plt.scatter(D0[:, 0], D0[:, 1], marker='s', s=50, edgecolor='k', label='Diminished')\n",
        "plt.plot(x1, x2, label='Decision Boundary')\n",
        "plt.xlabel(\"Engine Variable 1\")\n",
        "plt.ylabel(\"Engine Variable 2\")\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
